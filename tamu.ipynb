{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import *\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = './'\n",
    "\n",
    "image = \"./training-strips/cartoon1.png\"\n",
    "min-conf\n",
    "ap = argparse.ArgumentParser()\n",
    "\n",
    "ap.add_argument(\"-i\", \"--image\",\n",
    "\t\t\t\trequired=True,\n",
    "\t\t\t\thelp=\"path to input image to be OCR'd\")\n",
    "ap.add_argument(\"-c\", \"--min-conf\",\n",
    "\t\t\t\ttype=int, default=0,\n",
    "\t\t\t\thelp=\"minimum confidence value to filter weak text detection\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# We load the input image and then convert\n",
    "# it to RGB from BGR. We then use Tesseract\n",
    "# to localize each area of text in the input\n",
    "# image\n",
    "images = cv2.imread(args[\"image\"])\n",
    "rgb = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
    "results = pytesseract.image_to_data(rgb, output_type=Output.DICT)\n",
    "\n",
    "# Then loop over each of the individual text\n",
    "# localizations\n",
    "for i in range(0, len(results[\"text\"])):\n",
    "\t\n",
    "\t# We can then extract the bounding box coordinates\n",
    "\t# of the text region from the current result\n",
    "\tx = results[\"left\"][i]\n",
    "\ty = results[\"top\"][i]\n",
    "\tw = results[\"width\"][i]\n",
    "\th = results[\"height\"][i]\n",
    "\t\n",
    "\t# We will also extract the OCR text itself along\n",
    "\t# with the confidence of the text localization\n",
    "\ttext = results[\"text\"][i]\n",
    "\tconf = int(results[\"conf\"][i])\n",
    "\t\n",
    "\t# filter out weak confidence text localizations\n",
    "\tif conf > args[\"min_conf\"]:\n",
    "\t\t\n",
    "\t\t# We will display the confidence and text to\n",
    "\t\t# our terminal\n",
    "\t\tprint(\"Confidence: {}\".format(conf))\n",
    "\t\tprint(\"Text: {}\".format(text))\n",
    "\t\tprint(\"\")\n",
    "\t\t\n",
    "\t\t# We then strip out non-ASCII text so we can\n",
    "\t\t# draw the text on the image We will be using\n",
    "\t\t# OpenCV, then draw a bounding box around the\n",
    "\t\t# text along with the text itself\n",
    "\t\ttext = \"\".join(text).strip()\n",
    "\t\tcv2.rectangle(images,\n",
    "\t\t\t\t\t(x, y),\n",
    "\t\t\t\t\t(x + w, y + h),\n",
    "\t\t\t\t\t(0, 0, 255), 2)\n",
    "\t\tcv2.putText(images,\n",
    "\t\t\t\t\ttext,\n",
    "\t\t\t\t\t(x, y - 10),\n",
    "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t\t1.2, (0, 255, 255), 3)\n",
    "\t\t\n",
    "# After all, we will show the output image\n",
    "cv2.imshow(\"Image\", images)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c282428d11931fe85b58c4ff19c797595efa1422f09f58423a1cff9e85f11032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
